{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model, models, mixed_precision\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow_text\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_addons as tfa\n",
    "import glob\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "\n",
    "# all_files = glob.glob(\"*MA.csv\")\n",
    "# li = []\n",
    "# for filename in all_files:\n",
    "#     df = pd.read_csv(filename, index_col=None, header=0)\n",
    "#     li.append(df)\n",
    "#\n",
    "# df = pd.concat(li, axis=0, ignore_index=True)\n",
    "# df.dropna(inplace=True)\n",
    "# df = df[['chapter_name', 'qns']]\n",
    "# df.to_csv('all_qns.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('all_qns_merged_classes.csv')\n",
    "classes = df['chapter_name'].unique()\n",
    "classes_index = {v: i for i, v in enumerate(classes)}\n",
    "labeled_df = df.replace({'chapter_name': classes_index})\n",
    "labeled_df.rename(columns={'chapter_name': 'label'}, inplace=True)\n",
    "\n",
    "\n",
    "def clean(qns):\n",
    "    import re\n",
    "    qns = re.sub(r'[^\\x00-\\x7F]+', ' ', qns)  # clean unicode stuff\n",
    "    qns = re.sub(r'\\d+', ' 0 ', qns)  # replace all numbers with 0\n",
    "    qns = re.sub(r'_+', ' _ ', qns)  # replace all underscores with single underscore\n",
    "    qns = qns.split('(Note to students')[0].split('Notes to student')[0].split('Note to students')[0].split('Note to student')[0].split('Notes to students')[0].split('(Separate ')[0]  # strip hints/notes\n",
    "    qns = qns.strip()\n",
    "    return qns\n",
    "\n",
    "\n",
    "labeled_df['qns'] = labeled_df['qns'].apply(clean)\n",
    "labeled_df.dropna(inplace=True)\n",
    "labeled_df.to_csv('single_labeled_df.csv', index=False)\n",
    "labeled_df = labeled_df.sample(frac=1).reset_index(drop=True)  # shuffle\n",
    "labels_onehot = tf.keras.utils.to_categorical(labeled_df['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, patience=15, verbose=1,\n",
    "                                     mode='auto', baseline=None, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=12, verbose=1)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessing_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
    "encoder_inputs = preprocessing_layer(text_input)\n",
    "encoder = hub.KerasLayer('https://tfhub.dev/google/experts/bert/wiki_books/qnli/2', trainable=False)\n",
    "outputs = encoder(encoder_inputs)\n",
    "x = outputs['pooled_output']\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "xOut = Dense(len(classes))(x)\n",
    "model = Model(text_input, xOut)\n",
    "model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_type_ids':   0           ['input_1[0][0]']                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'pooled_output': (  109482241   ['keras_layer[0][0]',            \n",
      "                                None, 768),                       'keras_layer[0][1]',            \n",
      "                                 'sequence_output':               'keras_layer[0][2]']            \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'default': (None,                                                \n",
      "                                768)}                                                             \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer_1[0][13]']         \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          393728      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 512)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          131328      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 256)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 41)           10537       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 110,017,834\n",
      "Trainable params: 535,593\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 39s 797ms/step - loss: 2.9616 - accuracy: 0.2220 - val_loss: 2.5974 - val_accuracy: 0.3729 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 34s 945ms/step - loss: 2.5244 - accuracy: 0.3547 - val_loss: 2.2900 - val_accuracy: 0.4559 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 24s 685ms/step - loss: 2.2608 - accuracy: 0.4489 - val_loss: 2.0273 - val_accuracy: 0.5528 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 24s 675ms/step - loss: 2.0248 - accuracy: 0.5310 - val_loss: 1.8465 - val_accuracy: 0.6079 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 24s 679ms/step - loss: 1.8642 - accuracy: 0.5903 - val_loss: 1.7273 - val_accuracy: 0.6236 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 25s 685ms/step - loss: 1.7624 - accuracy: 0.6233 - val_loss: 1.6594 - val_accuracy: 0.6393 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 24s 661ms/step - loss: 1.6732 - accuracy: 0.6558 - val_loss: 1.5712 - val_accuracy: 0.6978 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 23s 638ms/step - loss: 1.6298 - accuracy: 0.6676 - val_loss: 1.5067 - val_accuracy: 0.7153 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 23s 652ms/step - loss: 1.5688 - accuracy: 0.7002 - val_loss: 1.4769 - val_accuracy: 0.7258 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 23s 639ms/step - loss: 1.5337 - accuracy: 0.7124 - val_loss: 1.4737 - val_accuracy: 0.7223 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 23s 640ms/step - loss: 1.4868 - accuracy: 0.7299 - val_loss: 1.4364 - val_accuracy: 0.7493 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 23s 648ms/step - loss: 1.4669 - accuracy: 0.7327 - val_loss: 1.4318 - val_accuracy: 0.7293 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 24s 668ms/step - loss: 1.4326 - accuracy: 0.7413 - val_loss: 1.4112 - val_accuracy: 0.7493 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 24s 659ms/step - loss: 1.4155 - accuracy: 0.7542 - val_loss: 1.3843 - val_accuracy: 0.7590 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 24s 661ms/step - loss: 1.3989 - accuracy: 0.7561 - val_loss: 1.3842 - val_accuracy: 0.7651 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 23s 650ms/step - loss: 1.3655 - accuracy: 0.7712 - val_loss: 1.3703 - val_accuracy: 0.7598 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 24s 666ms/step - loss: 1.3688 - accuracy: 0.7727 - val_loss: 1.3447 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 24s 667ms/step - loss: 1.3398 - accuracy: 0.7797 - val_loss: 1.3605 - val_accuracy: 0.7703 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 24s 658ms/step - loss: 1.3348 - accuracy: 0.7808 - val_loss: 1.3516 - val_accuracy: 0.7677 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 24s 664ms/step - loss: 1.3200 - accuracy: 0.7865 - val_loss: 1.3174 - val_accuracy: 0.7694 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 24s 667ms/step - loss: 1.3098 - accuracy: 0.7893 - val_loss: 1.3181 - val_accuracy: 0.7729 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 24s 666ms/step - loss: 1.2913 - accuracy: 0.8000 - val_loss: 1.3089 - val_accuracy: 0.7721 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 24s 663ms/step - loss: 1.2713 - accuracy: 0.8062 - val_loss: 1.2999 - val_accuracy: 0.7904 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 24s 658ms/step - loss: 1.2651 - accuracy: 0.8108 - val_loss: 1.2877 - val_accuracy: 0.7834 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 24s 659ms/step - loss: 1.2591 - accuracy: 0.8075 - val_loss: 1.2908 - val_accuracy: 0.7904 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 24s 660ms/step - loss: 1.2520 - accuracy: 0.8123 - val_loss: 1.2918 - val_accuracy: 0.7886 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 24s 668ms/step - loss: 1.2389 - accuracy: 0.8147 - val_loss: 1.2993 - val_accuracy: 0.7852 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 24s 671ms/step - loss: 1.2249 - accuracy: 0.8247 - val_loss: 1.2926 - val_accuracy: 0.7948 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 24s 665ms/step - loss: 1.2082 - accuracy: 0.8306 - val_loss: 1.2864 - val_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 24s 661ms/step - loss: 1.2140 - accuracy: 0.8282 - val_loss: 1.2719 - val_accuracy: 0.8017 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 24s 658ms/step - loss: 1.2032 - accuracy: 0.8326 - val_loss: 1.2747 - val_accuracy: 0.8052 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 24s 658ms/step - loss: 1.1943 - accuracy: 0.8387 - val_loss: 1.2680 - val_accuracy: 0.7965 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 24s 666ms/step - loss: 1.1985 - accuracy: 0.8324 - val_loss: 1.2804 - val_accuracy: 0.7948 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 24s 664ms/step - loss: 1.1748 - accuracy: 0.8472 - val_loss: 1.2718 - val_accuracy: 0.7983 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 24s 667ms/step - loss: 1.1808 - accuracy: 0.8429 - val_loss: 1.2669 - val_accuracy: 0.7921 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 24s 662ms/step - loss: 1.1733 - accuracy: 0.8433 - val_loss: 1.2537 - val_accuracy: 0.7991 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 24s 660ms/step - loss: 1.1660 - accuracy: 0.8464 - val_loss: 1.2724 - val_accuracy: 0.7886 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 24s 664ms/step - loss: 1.1653 - accuracy: 0.8501 - val_loss: 1.2757 - val_accuracy: 0.7930 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 24s 661ms/step - loss: 1.1554 - accuracy: 0.8527 - val_loss: 1.2594 - val_accuracy: 0.8026 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 23s 650ms/step - loss: 1.1426 - accuracy: 0.8523 - val_loss: 1.2641 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 24s 661ms/step - loss: 1.1446 - accuracy: 0.8593 - val_loss: 1.2592 - val_accuracy: 0.7939 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 24s 660ms/step - loss: 1.1393 - accuracy: 0.8630 - val_loss: 1.2590 - val_accuracy: 0.8000 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.1348 - accuracy: 0.8604\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "36/36 [==============================] - 24s 663ms/step - loss: 1.1348 - accuracy: 0.8604 - val_loss: 1.2570 - val_accuracy: 0.7948 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 24s 658ms/step - loss: 1.1107 - accuracy: 0.8693 - val_loss: 1.2284 - val_accuracy: 0.8052 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 24s 665ms/step - loss: 1.0791 - accuracy: 0.8785 - val_loss: 1.2253 - val_accuracy: 0.8087 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 24s 662ms/step - loss: 1.0740 - accuracy: 0.8851 - val_loss: 1.2243 - val_accuracy: 0.8070 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 24s 660ms/step - loss: 1.0705 - accuracy: 0.8851 - val_loss: 1.2222 - val_accuracy: 0.8070 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 24s 662ms/step - loss: 1.0671 - accuracy: 0.8837 - val_loss: 1.2195 - val_accuracy: 0.8087 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 24s 659ms/step - loss: 1.0694 - accuracy: 0.8840 - val_loss: 1.2186 - val_accuracy: 0.8079 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 24s 665ms/step - loss: 1.0582 - accuracy: 0.8892 - val_loss: 1.2205 - val_accuracy: 0.8070 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 24s 660ms/step - loss: 1.0563 - accuracy: 0.8955 - val_loss: 1.2202 - val_accuracy: 0.8096 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 23s 656ms/step - loss: 1.0606 - accuracy: 0.8872 - val_loss: 1.2166 - val_accuracy: 0.8087 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 24s 661ms/step - loss: 1.0687 - accuracy: 0.8805 - val_loss: 1.2193 - val_accuracy: 0.8114 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 24s 665ms/step - loss: 1.0597 - accuracy: 0.8877 - val_loss: 1.2167 - val_accuracy: 0.8140 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 24s 661ms/step - loss: 1.0535 - accuracy: 0.8914 - val_loss: 1.2184 - val_accuracy: 0.8079 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 24s 673ms/step - loss: 1.0610 - accuracy: 0.8816 - val_loss: 1.2159 - val_accuracy: 0.8122 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 24s 663ms/step - loss: 1.0618 - accuracy: 0.8877 - val_loss: 1.2142 - val_accuracy: 0.8122 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 24s 677ms/step - loss: 1.0563 - accuracy: 0.8861 - val_loss: 1.2145 - val_accuracy: 0.8175 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 24s 667ms/step - loss: 1.0502 - accuracy: 0.8938 - val_loss: 1.2167 - val_accuracy: 0.8140 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 24s 669ms/step - loss: 1.0526 - accuracy: 0.8894 - val_loss: 1.2185 - val_accuracy: 0.8131 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 24s 658ms/step - loss: 1.0455 - accuracy: 0.8962 - val_loss: 1.2151 - val_accuracy: 0.8114 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 24s 660ms/step - loss: 1.0529 - accuracy: 0.8923 - val_loss: 1.2173 - val_accuracy: 0.8148 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 24s 666ms/step - loss: 1.0524 - accuracy: 0.8866 - val_loss: 1.2146 - val_accuracy: 0.8122 - lr: 1.0000e-04\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 24s 670ms/step - loss: 1.0502 - accuracy: 0.8929 - val_loss: 1.2154 - val_accuracy: 0.8096 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 24s 663ms/step - loss: 1.0406 - accuracy: 0.8942 - val_loss: 1.2127 - val_accuracy: 0.8096 - lr: 1.0000e-04\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 24s 661ms/step - loss: 1.0488 - accuracy: 0.8958 - val_loss: 1.2173 - val_accuracy: 0.8096 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 24s 667ms/step - loss: 1.0477 - accuracy: 0.8925 - val_loss: 1.2180 - val_accuracy: 0.8114 - lr: 1.0000e-04\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 24s 660ms/step - loss: 1.0476 - accuracy: 0.8914 - val_loss: 1.2168 - val_accuracy: 0.8079 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 24s 673ms/step - loss: 1.0468 - accuracy: 0.8881 - val_loss: 1.2160 - val_accuracy: 0.8175 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.0493 - accuracy: 0.8947\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "36/36 [==============================] - 24s 665ms/step - loss: 1.0493 - accuracy: 0.8947 - val_loss: 1.2159 - val_accuracy: 0.8157 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 24s 667ms/step - loss: 1.0459 - accuracy: 0.8920 - val_loss: 1.2153 - val_accuracy: 0.8122 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 24s 666ms/step - loss: 1.0423 - accuracy: 0.8947 - val_loss: 1.2148 - val_accuracy: 0.8148 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.0402 - accuracy: 0.8979Restoring model weights from the end of the best epoch: 58.\n",
      "36/36 [==============================] - 24s 664ms/step - loss: 1.0402 - accuracy: 0.8979 - val_loss: 1.2147 - val_accuracy: 0.8131 - lr: 1.0000e-05\n",
      "Epoch 73: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x210ac94c340>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, show_dtype=True, show_shapes=True, show_layer_names=True, to_file='model.png')\n",
    "model.summary()\n",
    "model.fit(np.array(labeled_df['qns']), labels_onehot, batch_size=batch_size, epochs=epochs, callbacks=callbacks, verbose=1, use_multiprocessing=True, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predicted: Division with confidence 39.844%\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'Counting and number patterns': '1.356%',\n 'Place values': '1.532%',\n 'Addition': '8.942%',\n 'Subtraction': '4.453%',\n 'Comparing': '2.231%',\n 'Estimation': '0.802%',\n 'Shapes and Geometry': '0.576%',\n 'Spatial sense': '0.371%',\n 'Data graphs': '2.036%',\n 'Measurement': '0.597%',\n 'Money': '1.897%',\n 'Patterns': '0.925%',\n 'Probability and statistics': '3.000%',\n 'Sorting, ordering and classifying': '1.093%',\n 'Time': '1.410%',\n 'Mixed operations': '3.772%',\n 'Multiplication and division': '1.241%',\n 'Comparing and ordering': '3.372%',\n 'Names of numbers': '1.173%',\n 'Estimation and rounding': '0.499%',\n 'Logical reasoning': '0.257%',\n 'Fractions': '0.190%',\n 'Geometry': '0.230%',\n 'Exercise 1- Learning to interprete': '0.632%',\n 'Whole numbers and comparing': '1.218%',\n 'Multiplication': '1.321%',\n 'Division': '39.844%',\n 'Data and graphs': '1.042%',\n 'Whole Numbers': '1.524%',\n 'Decimals': '1.111%',\n 'Challenge': '0.515%',\n 'Whole Numbers & Fractions': '0.536%',\n 'Average': '0.366%',\n 'Ratio': '1.157%',\n 'Percentage': '0.732%',\n 'Area & Perimeter': '3.099%',\n 'Volume': '1.762%',\n 'Triangles': '0.787%',\n 'Ratio & Percentage': '0.760%',\n 'Speed': '0.402%',\n 'Circles': '1.230%'}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('model.h5')\n",
    "question = 'Billy is selling his penis for 5 cents per centimeter. How many centimeters of penis can you buy with 2 dollars'\n",
    "question = clean(question)\n",
    "softmax_out = Activation('softmax')(model(tf.constant([question]))).numpy()\n",
    "class_predicted = classes[np.argmax(softmax_out)]\n",
    "confidence = np.max(softmax_out)\n",
    "print(f'Class predicted: {class_predicted} with confidence {confidence*100:.3f}%')\n",
    "conf_list = {}\n",
    "for i in range(len(classes)):\n",
    "    conf_list.update({classes[i]: f'{softmax_out[0][i]*100:.3f}%'})\n",
    "\n",
    "conf_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}