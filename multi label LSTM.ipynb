{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3080 Ti, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model, models, mixed_precision\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow_text  # must import even if it is not used, else will have error\n",
    "import tensorflow_hub as hub\n",
    "import glob\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "\n",
    "# all_files = glob.glob(\"*MA.csv\")\n",
    "# li = []\n",
    "# for filename in all_files:\n",
    "#     df = pd.read_csv(filename, index_col=None, header=0)\n",
    "#     li.append(df)\n",
    "#\n",
    "# df = pd.concat(li, axis=0, ignore_index=True)\n",
    "# df.dropna(inplace=True)\n",
    "# df = df[['chapter_name', 'qns']]\n",
    "# df.to_csv('all_qns.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('all_qns_multi_label.csv')\n",
    "labels = df['chapter_name'].str.lower().tolist()\n",
    "labels = [[*i.split(',')] for i in labels]\n",
    "classes = []\n",
    "for i in labels:\n",
    "    for j in i:\n",
    "        if j not in classes:\n",
    "            classes.append(j)\n",
    "classes_index = {v: i for i, v in enumerate(classes)}\n",
    "def multi_hot_encode(label):\n",
    "    label_encoded = [classes_index[x] for x in label]\n",
    "    label_encoded = tf.reduce_max(tf.one_hot(label_encoded, len(classes)), axis=0)\n",
    "    return label_encoded\n",
    "\n",
    "labeled_df = pd.DataFrame()\n",
    "labels = [multi_hot_encode(i) for i in labels]\n",
    "\n",
    "def clean(qns):\n",
    "    import re\n",
    "    qns = re.sub(r'[^\\x00-\\x7F]+', ' ', qns)  # clean unicode stuff\n",
    "    qns = re.sub(r'\\d+', ' 0 ', qns)  # replace all numbers with 0\n",
    "    qns = re.sub(r'_+', ' _ ', qns)  # replace all underscores with single underscore\n",
    "    qns = qns.split('(Note to students')[0].split('Notes to student')[0].split('Note to students')[0].split('Note to student')[0].split('Notes to students')[0].split('(Separate ')[0]  # strip hints/notes\n",
    "    qns = qns.strip()\n",
    "    return qns\n",
    "\n",
    "\n",
    "qns = df['qns'].apply(clean)\n",
    "\n",
    "labeled_df['label'] = pd.Series(labels)\n",
    "labeled_df['qns'] = qns\n",
    "labeled_df.dropna(inplace=True)\n",
    "labeled_df.to_csv('multi_labeled_df.csv', index=False)\n",
    "\n",
    "# shuffle the dataset\n",
    "X, Y = shuffle(qns, labels)\n",
    "\n",
    "\n",
    "# labeled_df['label'] = pd.Series(labels)\n",
    "# labeled_df['qns'] = df['qns'].apply(clean)\n",
    "# labeled_df.dropna(inplace=True)\n",
    "# labeled_df.to_csv('multi_labeled_df.csv', index=False)\n",
    "# labeled_df = labeled_df.sample(frac=1).reset_index(drop=True)  # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# an accuracy metrics that excludes negative classes for each sample\n",
    "def positive_accuracy(y_true, y_pred):\n",
    "    thresh = 0.5\n",
    "    positive = y_true * y_pred\n",
    "    total_score = tf.reduce_sum(tf.cast(tf.greater_equal(positive, thresh), tf.float32))\n",
    "    acc = total_score / tf.reduce_sum(y_true)\n",
    "    return acc\n",
    "\n",
    "# weighted BCE\n",
    "def weighted_binary_crossentropy(pos_weight=1.):\n",
    "\n",
    "    # y_pred is the raw output of the logits layer\n",
    "    def _weighted_binary_crossentropy(y_true, y_pred):\n",
    "        return tf.keras.backend.mean(tf.nn.weighted_cross_entropy_with_logits(labels=y_true, logits=y_pred, pos_weight=pos_weight), axis=-1)\n",
    "    \n",
    "    return _weighted_binary_crossentropy\n",
    "\n",
    "loss = weighted_binary_crossentropy(pos_weight=15.)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_positive_accuracy', min_delta=0, patience=10, verbose=1,\n",
    "                                     mode='auto', baseline=None, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_positive_accuracy', factor=0.1, patience=3, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessing_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
    "encoder_inputs = preprocessing_layer(text_input)\n",
    "encoder = hub.KerasLayer('https://tfhub.dev/google/experts/bert/wiki_books/qnli/2', trainable=False)\n",
    "outputs = encoder(encoder_inputs)\n",
    "x = outputs['sequence_output']\n",
    "x = Bidirectional(LSTM(512, return_sequences=True))(x)\n",
    "x = LayerNormalization()(x)\n",
    "x = SpatialDropout1D(0.5)(x)\n",
    "x = Bidirectional(LSTM(256, return_sequences=False))(x)\n",
    "x = LayerNormalization()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "xOut = Dense(len(classes), activation=None)(x)\n",
    "model = Model(text_input, xOut)\n",
    "model.compile(loss=loss, optimizer=opt, metrics=['accuracy', positive_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_mask': (Non  0           ['input_1[0][0]']                \n",
      "                                e, 128),                                                          \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'default': (None,   109482241   ['keras_layer[0][0]',            \n",
      "                                768),                             'keras_layer[0][1]',            \n",
      "                                 'pooled_output': (               'keras_layer[0][2]']            \n",
      "                                None, 768),                                                       \n",
      "                                 'sequence_output':                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)]}                                               \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 128, 1024)    5246976     ['keras_layer_1[0][14]']         \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 128, 1024)   2048        ['bidirectional[0][0]']          \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " spatial_dropout1d (SpatialDrop  (None, 128, 1024)   0           ['layer_normalization[0][0]']    \n",
      " out1D)                                                                                           \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, 512)         2623488     ['spatial_dropout1d[0][0]']      \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " layer_normalization_1 (LayerNo  (None, 512)         1024        ['bidirectional_1[0][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          131328      ['layer_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 256)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 36)           9252        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 117,496,357\n",
      "Trainable params: 8,014,116\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/15\n",
      "36/36 [==============================] - 24s 677ms/step - loss: 0.1647 - accuracy: 0.6665 - positive_accuracy: 0.9216 - val_loss: 0.1829 - val_accuracy: 0.6576 - val_positive_accuracy: 0.9254 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "36/36 [==============================] - 24s 666ms/step - loss: 0.1626 - accuracy: 0.6606 - positive_accuracy: 0.9240 - val_loss: 0.1677 - val_accuracy: 0.6620 - val_positive_accuracy: 0.9212 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "36/36 [==============================] - 24s 666ms/step - loss: 0.1566 - accuracy: 0.6652 - positive_accuracy: 0.9255 - val_loss: 0.1763 - val_accuracy: 0.6812 - val_positive_accuracy: 0.9203 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1537 - accuracy: 0.6755 - positive_accuracy: 0.9304\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "36/36 [==============================] - 24s 668ms/step - loss: 0.1537 - accuracy: 0.6755 - positive_accuracy: 0.9304 - val_loss: 0.1549 - val_accuracy: 0.6865 - val_positive_accuracy: 0.9203 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "36/36 [==============================] - 24s 670ms/step - loss: 0.1422 - accuracy: 0.6805 - positive_accuracy: 0.9349 - val_loss: 0.1508 - val_accuracy: 0.6707 - val_positive_accuracy: 0.9323 - lr: 1.0000e-04\n",
      "Epoch 6/15\n",
      "36/36 [==============================] - 24s 669ms/step - loss: 0.1305 - accuracy: 0.6967 - positive_accuracy: 0.9462 - val_loss: 0.1524 - val_accuracy: 0.6803 - val_positive_accuracy: 0.9280 - lr: 1.0000e-04\n",
      "Epoch 7/15\n",
      "36/36 [==============================] - 24s 675ms/step - loss: 0.1259 - accuracy: 0.6995 - positive_accuracy: 0.9504 - val_loss: 0.1532 - val_accuracy: 0.6821 - val_positive_accuracy: 0.9237 - lr: 1.0000e-04\n",
      "Epoch 8/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1223 - accuracy: 0.7124 - positive_accuracy: 0.9519\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "36/36 [==============================] - 25s 687ms/step - loss: 0.1223 - accuracy: 0.7124 - positive_accuracy: 0.9519 - val_loss: 0.1532 - val_accuracy: 0.6786 - val_positive_accuracy: 0.9225 - lr: 1.0000e-04\n",
      "Epoch 9/15\n",
      "36/36 [==============================] - 24s 677ms/step - loss: 0.1223 - accuracy: 0.7131 - positive_accuracy: 0.9509 - val_loss: 0.1528 - val_accuracy: 0.6769 - val_positive_accuracy: 0.9204 - lr: 1.0000e-05\n",
      "Epoch 10/15\n",
      "36/36 [==============================] - 25s 688ms/step - loss: 0.1180 - accuracy: 0.7074 - positive_accuracy: 0.9566 - val_loss: 0.1529 - val_accuracy: 0.6742 - val_positive_accuracy: 0.9211 - lr: 1.0000e-05\n",
      "Epoch 11/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.7190 - positive_accuracy: 0.9551\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "36/36 [==============================] - 25s 694ms/step - loss: 0.1172 - accuracy: 0.7190 - positive_accuracy: 0.9551 - val_loss: 0.1528 - val_accuracy: 0.6786 - val_positive_accuracy: 0.9218 - lr: 1.0000e-05\n",
      "Epoch 12/15\n",
      "36/36 [==============================] - 25s 712ms/step - loss: 0.1174 - accuracy: 0.7157 - positive_accuracy: 0.9547 - val_loss: 0.1528 - val_accuracy: 0.6777 - val_positive_accuracy: 0.9218 - lr: 1.0000e-06\n",
      "Epoch 13/15\n",
      "36/36 [==============================] - 25s 685ms/step - loss: 0.1202 - accuracy: 0.7089 - positive_accuracy: 0.9539 - val_loss: 0.1527 - val_accuracy: 0.6777 - val_positive_accuracy: 0.9218 - lr: 1.0000e-06\n",
      "Epoch 14/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.7096 - positive_accuracy: 0.9508\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "36/36 [==============================] - 24s 677ms/step - loss: 0.1194 - accuracy: 0.7096 - positive_accuracy: 0.9508 - val_loss: 0.1527 - val_accuracy: 0.6777 - val_positive_accuracy: 0.9218 - lr: 1.0000e-06\n",
      "Epoch 15/15\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1191 - accuracy: 0.7115 - positive_accuracy: 0.9538Restoring model weights from the end of the best epoch: 5.\n",
      "36/36 [==============================] - 24s 673ms/step - loss: 0.1191 - accuracy: 0.7115 - positive_accuracy: 0.9538 - val_loss: 0.1528 - val_accuracy: 0.6777 - val_positive_accuracy: 0.9218 - lr: 1.0000e-07\n",
      "Epoch 15: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2bfc76823a0>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, show_dtype=True, show_shapes=True, show_layer_names=True, to_file='lstm_model.png')\n",
    "model.summary()\n",
    "model.fit(np.array(X), np.array(Y), batch_size=batch_size, epochs=epochs, callbacks=callbacks, verbose=1, use_multiprocessing=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save('multi_label_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: KerasLayer. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_22884/420757179.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mmodels\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'multi_label_77_90.h5'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mquestion\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'Billy is selling his penis for 5 cents per centimeter. How many centimeters of penis can you buy with 2 dollars?'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mquestion\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mclean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mquestion\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0msigmoid_out\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mActivation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'sigmoid'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconstant\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mquestion\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mconfidence\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwhere\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgreater_equal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msigmoid_out\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Program Files\\Python39\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001B[0m in \u001B[0;36mclass_and_config_for_serialized_keras_object\u001B[1;34m(config, module_objects, custom_objects, printable_module_name)\u001B[0m\n\u001B[0;32m    560\u001B[0m   \u001B[0mcls\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_registered_object\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclass_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcustom_objects\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodule_objects\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    561\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0mcls\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 562\u001B[1;33m     raise ValueError(\n\u001B[0m\u001B[0;32m    563\u001B[0m         \u001B[1;34mf'Unknown {printable_module_name}: {class_name}. Please ensure this '\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    564\u001B[0m         \u001B[1;34m'object is passed to the `custom_objects` argument. See '\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: Unknown layer: KerasLayer. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "models.load_model('multi_label_lstm')\n",
    "question = 'Billy is selling his penis for 5 cents per centimeter. How many centimeters of penis can you buy with 2 dollars?'\n",
    "question = clean(question)\n",
    "sigmoid_out = Activation('sigmoid')(model(tf.constant([question])).numpy()[0])\n",
    "confidence = tf.where(tf.greater_equal(sigmoid_out, 0.5)).numpy()\n",
    "class_predicted = [classes[i[0]] for i in confidence]\n",
    "for class_, conf in zip(class_predicted, confidence):\n",
    "    print(f'Class predicted: {class_} with confidence {sigmoid_out[conf[0]]*100:.3f}%')\n",
    "conf_list = {}\n",
    "for i in range(len(classes)):\n",
    "    conf_list.update({classes[i]: f'{sigmoid_out[i]*100:.3f}%'})\n",
    "\n",
    "conf_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}