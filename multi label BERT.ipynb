{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3080 Ti, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Model, models, mixed_precision\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow_text  # must import even if it is not used, else will have error\n",
    "import tensorflow_hub as hub\n",
    "import glob\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "\n",
    "# all_files = glob.glob(\"*MA.csv\")\n",
    "# li = []\n",
    "# for filename in all_files:\n",
    "#     df = pd.read_csv(filename, index_col=None, header=0)\n",
    "#     li.append(df)\n",
    "#\n",
    "# df = pd.concat(li, axis=0, ignore_index=True)\n",
    "# df.dropna(inplace=True)\n",
    "# df = df[['chapter_name', 'qns']]\n",
    "# df.to_csv('all_qns.csv', index=False)\n",
    "\n",
    "df = pd.read_csv('all_qns_multi_label.csv')\n",
    "labels = df['chapter_name'].str.lower().tolist()\n",
    "labels = [[*i.split(',')] for i in labels]\n",
    "classes = []\n",
    "for i in labels:\n",
    "    for j in i:\n",
    "        if j not in classes:\n",
    "            classes.append(j)\n",
    "classes_index = {v: i for i, v in enumerate(classes)}\n",
    "def multi_hot_encode(label):\n",
    "    label_encoded = [classes_index[x] for x in label]\n",
    "    label_encoded = tf.reduce_max(tf.one_hot(label_encoded, len(classes)), axis=0)\n",
    "    return label_encoded\n",
    "\n",
    "labeled_df = pd.DataFrame()\n",
    "labels = [multi_hot_encode(i) for i in labels]\n",
    "\n",
    "def clean(qns):\n",
    "    import re\n",
    "    qns = re.sub(r'[^\\x00-\\x7F]+', ' ', qns)  # clean unicode stuff\n",
    "    qns = re.sub(r'\\d+', ' 0 ', qns)  # replace all numbers with 0\n",
    "    qns = re.sub(r'_+', ' _ ', qns)  # replace all underscores with single underscore\n",
    "    qns = qns.split('(Note to students')[0].split('Notes to student')[0].split('Note to students')[0].split('Note to student')[0].split('Notes to students')[0].split('(Separate ')[0]  # strip hints/notes\n",
    "    qns = qns.strip()\n",
    "    return qns\n",
    "\n",
    "\n",
    "qns = df['qns'].apply(clean)\n",
    "\n",
    "labeled_df['label'] = pd.Series(labels)\n",
    "labeled_df['qns'] = qns\n",
    "labeled_df.dropna(inplace=True)\n",
    "labeled_df.to_csv('multi_labeled_df.csv', index=False)\n",
    "\n",
    "# shuffle the dataset\n",
    "X, Y = shuffle(qns, labels)\n",
    "\n",
    "\n",
    "# labeled_df['label'] = pd.Series(labels)\n",
    "# labeled_df['qns'] = df['qns'].apply(clean)\n",
    "# labeled_df.dropna(inplace=True)\n",
    "# labeled_df.to_csv('multi_labeled_df.csv', index=False)\n",
    "# labeled_df = labeled_df.sample(frac=1).reset_index(drop=True)  # shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# an accuracy metrics that excludes negative classes for each sample\n",
    "def positive_accuracy(y_true, y_pred):\n",
    "    thresh = 0.5\n",
    "    positive = y_true * y_pred\n",
    "    total_score = tf.reduce_sum(tf.cast(tf.greater_equal(positive, thresh), tf.float32))\n",
    "    acc = total_score / tf.reduce_sum(y_true)\n",
    "    return acc\n",
    "\n",
    "# weighted BCE\n",
    "def weighted_binary_crossentropy(pos_weight=1.):\n",
    "\n",
    "    # y_pred is the raw output of the logits layer\n",
    "    def _weighted_binary_crossentropy(y_true, y_pred):\n",
    "        return tf.keras.backend.mean(tf.nn.weighted_cross_entropy_with_logits(labels=y_true, logits=y_pred, pos_weight=pos_weight), axis=-1)\n",
    "    \n",
    "    return _weighted_binary_crossentropy\n",
    "\n",
    "loss = weighted_binary_crossentropy(pos_weight=15.)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_positive_accuracy', min_delta=0, patience=13, verbose=1,\n",
    "                                     mode='auto', baseline=None, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_positive_accuracy', factor=0.1, patience=10, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string)\n",
    "preprocessing_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
    "encoder_inputs = preprocessing_layer(text_input)\n",
    "encoder = hub.KerasLayer('https://tfhub.dev/google/experts/bert/wiki_books/qnli/2', trainable=False)\n",
    "outputs = encoder(encoder_inputs)\n",
    "x = outputs['pooled_output']\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "xOut = Dense(len(classes), activation=None)(x)\n",
    "model = Model(text_input, xOut)\n",
    "model.compile(loss=loss, optimizer=opt, metrics=['accuracy', positive_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'input_mask': (Non  0           ['input_1[0][0]']                \n",
      "                                e, 128),                                                          \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'sequence_output':  109482241   ['keras_layer[0][0]',            \n",
      "                                 (None, 128, 768),                'keras_layer[0][1]',            \n",
      "                                 'default': (None,                'keras_layer[0][2]']            \n",
      "                                768),                                                             \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768),                                                       \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)]}                                               \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 768)          0           ['keras_layer_1[0][13]']         \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          393728      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 512)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          262656      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 512)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 36)           18468       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 110,157,093\n",
      "Trainable params: 674,852\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "36/36 [==============================] - 37s 749ms/step - loss: 0.6860 - accuracy: 0.2185 - positive_accuracy: 0.4653 - val_loss: 0.5463 - val_accuracy: 0.3205 - val_positive_accuracy: 0.5958 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 32s 901ms/step - loss: 0.5181 - accuracy: 0.3269 - positive_accuracy: 0.6149 - val_loss: 0.4515 - val_accuracy: 0.4061 - val_positive_accuracy: 0.7024 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 23s 631ms/step - loss: 0.4295 - accuracy: 0.4023 - positive_accuracy: 0.7023 - val_loss: 0.3838 - val_accuracy: 0.4681 - val_positive_accuracy: 0.8201 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 23s 631ms/step - loss: 0.3648 - accuracy: 0.4849 - positive_accuracy: 0.7737 - val_loss: 0.3303 - val_accuracy: 0.5214 - val_positive_accuracy: 0.8554 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 22s 626ms/step - loss: 0.3176 - accuracy: 0.5205 - positive_accuracy: 0.8043 - val_loss: 0.2903 - val_accuracy: 0.5345 - val_positive_accuracy: 0.8691 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 22s 619ms/step - loss: 0.2902 - accuracy: 0.5498 - positive_accuracy: 0.8272 - val_loss: 0.2758 - val_accuracy: 0.6323 - val_positive_accuracy: 0.8650 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 22s 625ms/step - loss: 0.2576 - accuracy: 0.5972 - positive_accuracy: 0.8521 - val_loss: 0.2557 - val_accuracy: 0.6227 - val_positive_accuracy: 0.8841 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 22s 625ms/step - loss: 0.2338 - accuracy: 0.6045 - positive_accuracy: 0.8689 - val_loss: 0.2355 - val_accuracy: 0.6480 - val_positive_accuracy: 0.8868 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 22s 622ms/step - loss: 0.2268 - accuracy: 0.6228 - positive_accuracy: 0.8728 - val_loss: 0.2305 - val_accuracy: 0.6253 - val_positive_accuracy: 0.8860 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 22s 625ms/step - loss: 0.2099 - accuracy: 0.6469 - positive_accuracy: 0.8851 - val_loss: 0.2144 - val_accuracy: 0.6803 - val_positive_accuracy: 0.9040 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 22s 620ms/step - loss: 0.1976 - accuracy: 0.6611 - positive_accuracy: 0.8958 - val_loss: 0.2122 - val_accuracy: 0.6594 - val_positive_accuracy: 0.8923 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 22s 621ms/step - loss: 0.1891 - accuracy: 0.6777 - positive_accuracy: 0.8934 - val_loss: 0.2079 - val_accuracy: 0.6463 - val_positive_accuracy: 0.8996 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 22s 624ms/step - loss: 0.1826 - accuracy: 0.6733 - positive_accuracy: 0.9019 - val_loss: 0.2039 - val_accuracy: 0.6638 - val_positive_accuracy: 0.8864 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 23s 629ms/step - loss: 0.1672 - accuracy: 0.6951 - positive_accuracy: 0.9122 - val_loss: 0.1946 - val_accuracy: 0.7118 - val_positive_accuracy: 0.9127 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 22s 624ms/step - loss: 0.1655 - accuracy: 0.6943 - positive_accuracy: 0.9148 - val_loss: 0.1996 - val_accuracy: 0.6716 - val_positive_accuracy: 0.8898 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 22s 620ms/step - loss: 0.1561 - accuracy: 0.6973 - positive_accuracy: 0.9185 - val_loss: 0.1954 - val_accuracy: 0.6917 - val_positive_accuracy: 0.9013 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 22s 628ms/step - loss: 0.1566 - accuracy: 0.7048 - positive_accuracy: 0.9187 - val_loss: 0.1830 - val_accuracy: 0.7100 - val_positive_accuracy: 0.9177 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 22s 623ms/step - loss: 0.1478 - accuracy: 0.7076 - positive_accuracy: 0.9308 - val_loss: 0.1888 - val_accuracy: 0.6795 - val_positive_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 22s 619ms/step - loss: 0.1454 - accuracy: 0.7229 - positive_accuracy: 0.9290 - val_loss: 0.1825 - val_accuracy: 0.6891 - val_positive_accuracy: 0.9047 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 22s 618ms/step - loss: 0.1396 - accuracy: 0.7188 - positive_accuracy: 0.9301 - val_loss: 0.1811 - val_accuracy: 0.6917 - val_positive_accuracy: 0.9163 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 22s 620ms/step - loss: 0.1355 - accuracy: 0.7273 - positive_accuracy: 0.9345 - val_loss: 0.1812 - val_accuracy: 0.6969 - val_positive_accuracy: 0.9076 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 22s 620ms/step - loss: 0.1323 - accuracy: 0.7303 - positive_accuracy: 0.9368 - val_loss: 0.1807 - val_accuracy: 0.7057 - val_positive_accuracy: 0.9077 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 22s 619ms/step - loss: 0.1311 - accuracy: 0.7275 - positive_accuracy: 0.9372 - val_loss: 0.1714 - val_accuracy: 0.7275 - val_positive_accuracy: 0.9112 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 22s 622ms/step - loss: 0.1275 - accuracy: 0.7371 - positive_accuracy: 0.9367 - val_loss: 0.1829 - val_accuracy: 0.6786 - val_positive_accuracy: 0.8913 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 22s 619ms/step - loss: 0.1206 - accuracy: 0.7421 - positive_accuracy: 0.9417 - val_loss: 0.1836 - val_accuracy: 0.7336 - val_positive_accuracy: 0.8953 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 22s 620ms/step - loss: 0.1196 - accuracy: 0.7430 - positive_accuracy: 0.9423 - val_loss: 0.1787 - val_accuracy: 0.7162 - val_positive_accuracy: 0.9091 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.7461 - positive_accuracy: 0.9440\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "36/36 [==============================] - 22s 618ms/step - loss: 0.1215 - accuracy: 0.7461 - positive_accuracy: 0.9440 - val_loss: 0.1770 - val_accuracy: 0.6751 - val_positive_accuracy: 0.9163 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 22s 621ms/step - loss: 0.1069 - accuracy: 0.7458 - positive_accuracy: 0.9575 - val_loss: 0.1738 - val_accuracy: 0.7074 - val_positive_accuracy: 0.9077 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 22s 621ms/step - loss: 0.1014 - accuracy: 0.7638 - positive_accuracy: 0.9582 - val_loss: 0.1705 - val_accuracy: 0.7223 - val_positive_accuracy: 0.9070 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0989 - accuracy: 0.7701 - positive_accuracy: 0.9561Restoring model weights from the end of the best epoch: 17.\n",
      "36/36 [==============================] - 22s 622ms/step - loss: 0.0989 - accuracy: 0.7701 - positive_accuracy: 0.9561 - val_loss: 0.1710 - val_accuracy: 0.7188 - val_positive_accuracy: 0.9127 - lr: 1.0000e-04\n",
      "Epoch 30: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x23dad41bf10>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, show_dtype=True, show_shapes=True, show_layer_names=True, to_file='bert_model.png')\n",
    "model.summary()\n",
    "model.fit(np.array(X), np.array(Y), batch_size=batch_size, epochs=epochs, callbacks=callbacks, verbose=1, use_multiprocessing=True, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 360). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: multi_label\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: multi_label\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('multi_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class predicted: shapes with confidence 92.750%\n",
      "Class predicted: geometry with confidence 96.125%\n",
      "Class predicted: circles with confidence 77.438%\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'counting': '0.006%',\n 'patterns': '0.203%',\n 'place values': '0.065%',\n 'addition': '0.017%',\n 'subtraction': '0.044%',\n 'comparing': '0.007%',\n 'estimation': '0.018%',\n 'shapes': '92.750%',\n 'geometry': '96.125%',\n 'spatial sense': '0.948%',\n 'data graphs': '0.339%',\n 'measurement': '0.089%',\n 'money': '0.004%',\n 'probability and statistics': '10.281%',\n 'ordering': '0.000%',\n 'classifying': '0.000%',\n 'time': '0.008%',\n 'mixed operations': '0.007%',\n 'multiplication': '0.005%',\n 'division': '0.011%',\n 'names of numbers': '0.054%',\n 'estimation and rounding': '0.004%',\n 'logical reasoning': '26.859%',\n 'fractions': '0.355%',\n 'learning to interprete': '0.125%',\n 'whole numbers': '6.914%',\n 'decimals': '0.045%',\n 'ratio': '25.172%',\n 'challenge': '0.007%',\n 'average': '0.997%',\n 'percentage': '1.764%',\n 'area & perimeter': '9.555%',\n 'volume': '17.125%',\n 'triangles': '24.062%',\n 'speed': '0.247%',\n 'circles': '77.438%'}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'The height of an isosceles triangle with a base length of 8cm is 3cm. What is the perimeter of a similar triangle with base 4cm?'\n",
    "question = clean(question)\n",
    "sigmoid_out = Activation('sigmoid')(model(tf.constant([question])).numpy()[0])\n",
    "confidence = tf.where(tf.greater_equal(sigmoid_out, 0.5)).numpy()\n",
    "class_predicted = [classes[i[0]] for i in confidence]\n",
    "for class_, conf in zip(class_predicted, confidence):\n",
    "    print(f'Class predicted: {class_} with confidence {sigmoid_out[conf[0]]*100:.3f}%')\n",
    "conf_list = {}\n",
    "for i in range(len(classes)):\n",
    "    conf_list.update({classes[i]: f'{sigmoid_out[i]*100:.3f}%'})\n",
    "\n",
    "conf_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}